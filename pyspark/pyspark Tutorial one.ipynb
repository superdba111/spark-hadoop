{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815d5015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Glue Interactive Sessions Kernel\n",
      "For more information on available magic commands, please type %help in any new cell.\n",
      "\n",
      "Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
      "Previous profile: default\n",
      "Setting new profile to: de\n"
     ]
    }
   ],
   "source": [
    "%profile \"de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb903420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting Glue version to: 3.0\n"
     ]
    }
   ],
   "source": [
    "%glue_version 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb99161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous number of workers: 5\n",
      "Setting new number of workers to: 2\n"
     ]
    }
   ],
   "source": [
    "%number_of_workers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d7627c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iam_role is None\n",
      "iam_role has been set to arn:aws:iam::1234567890123:role/LakeFormationWorkflowRole.\n"
     ]
    }
   ],
   "source": [
    "%iam_role arn:aws:iam::1234567890123:role/LakeFormationWorkflowRole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "c30e49fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating with profile=de\n",
      "glue_role_arn defined by user: arn:aws:iam::1234567890123:role/LakeFormationWorkflowRole\n",
      "Trying to create a Glue session for the kernel.\n",
      "Worker Type: G.1X\n",
      "Number of Workers: 2\n",
      "Session ID: d18a59ea-bc8e-43ff-af5b-6848fd11239f\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 0.31\n",
      "--enable-glue-datacatalog true\n",
      "Waiting for session d18a59ea-bc8e-43ff-af5b-6848fd11239f to get into ready status...\n",
      "Session d18a59ea-bc8e-43ff-af5b-6848fd11239f has been created\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30a5928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'3.1.1-amzn-0'\n"
     ]
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc539c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'3.7'\n"
     ]
    }
   ],
   "source": [
    "sc.pythonVer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1388f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'jes'\n"
     ]
    }
   ],
   "source": [
    "sc.master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea6e9b",
   "metadata": {},
   "source": [
    "Create DF ---https://sparkbyexamples.com/pyspark/different-ways-to-create-dataframe-in-pyspark/; RDD is outdated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16f1b825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = [('James','','Smith','1991-04-01','M',3000),\n",
    "  ('Michael','Rose','','2000-05-19','M',4000),\n",
    "  ('Robert','','Williams','1978-09-05','M',4000),\n",
    "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
    "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data=data, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c2e71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+----------+------+------+\n",
      "|firstname|middlename|lastname|       dob|gender|salary|\n",
      "+---------+----------+--------+----------+------+------+\n",
      "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
      "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
      "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
      "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
      "+---------+----------+--------+----------+------+------+\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d0e9ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|id   |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "data2 = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])\n",
    " \n",
    "df = spark.createDataFrame(data=data2,schema=schema)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61287279",
   "metadata": {},
   "source": [
    "syntax for readinf files\n",
    "\n",
    "df2 = spark.read.csv(\"/src/resources/file.csv\")\n",
    "\n",
    "df2 = spark.read.text(\"/src/resources/file.txt\")\n",
    "\n",
    "df2 = spark.read.json(\"/src/resources/file.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c528ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|   James |          |   Smith|36636|     M|  3000|\n",
      "| Michael |      Rose|        |40288|     M|  4000|\n",
      "|  Robert |          |Williams|42114|     M|  4000|\n",
      "|   Maria |      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data =[(\"James \",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "              (\"Michael \",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "              (\"Robert \",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "              (\"Maria \",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
    "columns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
    "df=spark.createDataFrame(data,columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "053d249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df.write.parquet(\"s3://einc-s3-compounds-dev/pyspark/people.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fee4e6",
   "metadata": {},
   "source": [
    "â¯ aws s3 ls s3://einc-s3-compounds-dev/pyspark/people.parquet/\n",
    "2022-05-31 21:56:20       1538 part-00000-797e6789-4fed-4e5f-9e0a-462a8fd72dbc-c000.snappy.parquet\n",
    "2022-05-31 21:56:20       1545 part-00001-797e6789-4fed-4e5f-9e0a-462a8fd72dbc-c000.snappy.parquet\n",
    "2022-05-31 21:56:20       1574 part-00002-797e6789-4fed-4e5f-9e0a-462a8fd72dbc-c000.snappy.parquet\n",
    "2022-05-31 21:56:20       1498 part-00003-797e6789-4fed-4e5f-9e0a-462a8fd72dbc-c000.snappy.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa247672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parDF1=spark.read.parquet(\"s3://einc-s3-compounds-dev/pyspark/people.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0e41394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|  dob|gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|  Robert |          |Williams|42114|     M|  4000|\n",
      "| Michael |      Rose|        |40288|     M|  4000|\n",
      "|   James |          |   Smith|36636|     M|  3000|\n",
      "|   Maria |      Anne|   Jones|39192|     F|  4000|\n",
      "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
      "+---------+----------+--------+-----+------+------+\n"
     ]
    }
   ],
   "source": [
    "parDF1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2370375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- middlename: string (nullable = true)\n",
      " |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|dob  |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|James    |          |Smith   |36636|M     |3000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
      "+---------+----------+--------+-----+------+------+\n"
     ]
    }
   ],
   "source": [
    "parDF1.createOrReplaceTempView(\"parquetTable\")\n",
    "parDF1.printSchema()\n",
    "parDF1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bd68031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+------+\n",
      "|firstname|middlename|lastname|dob  |gender|salary|\n",
      "+---------+----------+--------+-----+------+------+\n",
      "|Robert   |          |Williams|42114|M     |4000  |\n",
      "|Michael  |Rose      |        |40288|M     |4000  |\n",
      "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
      "+---------+----------+--------+-----+------+------+\n"
     ]
    }
   ],
   "source": [
    "parkSQL = spark.sql(\"select * from ParquetTable where salary >= 4000 \")\n",
    "parkSQL.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5167fe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"CREATE TEMPORARY VIEW PERSON USING parquet OPTIONS (path \\\"/tmp/output/people.parquet\\\")\")\n",
    "# spark.sql(\"SELECT * FROM PERSON\").show()\n",
    "\n",
    "df.write.partitionBy(\"gender\",\"salary\").mode(\"overwrite\").parquet(\"s3://einc-s3-compounds-dev/pyspark/people2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "397c8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+------+\n",
      "|firstname|middlename|lastname|dob  |salary|\n",
      "+---------+----------+--------+-----+------+\n",
      "|Robert   |          |Williams|42114|4000  |\n",
      "|Michael  |Rose      |        |40288|4000  |\n",
      "|James    |          |Smith   |36636|3000  |\n",
      "+---------+----------+--------+-----+------+\n"
     ]
    }
   ],
   "source": [
    "parDF2=spark.read.parquet(\"s3://einc-s3-compounds-dev/pyspark/people2.parquet/gender=M\")\n",
    "parDF2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c42e543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(\"CREATE TEMPORARY VIEW PERSON2 USING parquet OPTIONS (path \\\"/tmp/output/people2.parquet/gender=F\\\")\")\n",
    "# spark.sql(\"SELECT * FROM PERSON2\" ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac4464",
   "metadata": {},
   "source": [
    "https://sparkbyexamples.com/pyspark-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91da3ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  firstname middlename  lastname    dob  salary\n",
      "0   Robert              Williams  42114    4000\n",
      "1  Michael        Rose            40288    4000\n",
      "2    James                 Smith  36636    3000\n"
     ]
    }
   ],
   "source": [
    "pandasDF = parDF2.toPandas()\n",
    "print(pandasDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "246ec251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n",
      "+--------------------+-----+------+------+\n",
      "|                name|  dob|gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|    {James, , Smith}|36636|     M|  3000|\n",
      "|   {Michael, Rose, }|40288|     M|  4000|\n",
      "|{Robert, , Williams}|42114|     M|  4000|\n",
      "|{Maria, Anne, Jones}|39192|     F|  4000|\n",
      "|  {Jen, Mary, Brown}|     |     F|    -1|\n",
      "+--------------------+-----+------+------+\n",
      "\n",
      "                   name    dob gender salary\n",
      "0      (James, , Smith)  36636      M   3000\n",
      "1     (Michael, Rose, )  40288      M   4000\n",
      "2  (Robert, , Williams)  42114      M   4000\n",
      "3  (Maria, Anne, Jones)  39192      F   4000\n",
      "4    (Jen, Mary, Brown)             F     -1\n"
     ]
    }
   ],
   "source": [
    "# Nested structure elements\n",
    "from pyspark.sql.types import StructType, StructField, StringType,IntegerType\n",
    "dataStruct = [((\"James\",\"\",\"Smith\"),\"36636\",\"M\",\"3000\"), \\\n",
    "      ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",\"4000\"), \\\n",
    "      ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",\"4000\"), \\\n",
    "      ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",\"4000\"), \\\n",
    "      ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",\"-1\") \\\n",
    "]\n",
    "\n",
    "schemaStruct = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "          StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', StringType(), True)\n",
    "         ])\n",
    "df = spark.createDataFrame(data=dataStruct, schema = schemaStruct)\n",
    "df.printSchema()\n",
    "df.show()\n",
    "\n",
    "pandasDF2 = df.toPandas()\n",
    "print(pandasDF2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ebc1b",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba4582b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "+--------------------+----------+------+------+\n",
      "|                name|       dob|gender|salary|\n",
      "+--------------------+----------+------+------+\n",
      "|    {James, , Smith}|1991-04-01|     M|  3000|\n",
      "|   {Michael, Rose, }|2000-05-19|     M|  4000|\n",
      "|{Robert, , Williams}|1978-09-05|     M|  4000|\n",
      "|{Maria, Anne, Jones}|1967-12-01|     F|  4000|\n",
      "|  {Jen, Mary, Brown}|1980-02-17|     F|    -1|\n",
      "+--------------------+----------+------+------+\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
    "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
    "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
    "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
    "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('dob', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df = spark.createDataFrame(data = dataDF, schema = schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e9a672a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "df.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ca7de4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- DateOfBirth: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary_amount: integer (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "# Example 2   \n",
    "df2 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
    "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "107f25c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "# Example 3 \n",
    "schema2 = StructType([\n",
    "    StructField(\"fname\",StringType()),\n",
    "    StructField(\"middlename\",StringType()),\n",
    "    StructField(\"lname\",StringType())])\n",
    "    \n",
    "df.select(col(\"name\").cast(schema2),\n",
    "  col(\"dob\"),\n",
    "  col(\"gender\"),\n",
    "  col(\"salary\")) \\\n",
    "    .printSchema()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adc460e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "# Example 4 \n",
    "df.select(col(\"name.firstname\").alias(\"fname\"),\n",
    "  col(\"name.middlename\").alias(\"mname\"),\n",
    "  col(\"name.lastname\").alias(\"lname\"),\n",
    "  col(\"dob\"),col(\"gender\"),col(\"salary\")) \\\n",
    "  .printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd5bc3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dob: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- mname: string (nullable = true)\n",
      " |-- lname: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "# Example 5\n",
    "df4 = df.withColumn(\"fname\",col(\"name.firstname\")) \\\n",
    "      .withColumn(\"mname\",col(\"name.middlename\")) \\\n",
    "      .withColumn(\"lname\",col(\"name.lastname\")) \\\n",
    "      .drop(\"name\")\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb6df6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- newCol1: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- newCol2: string (nullable = true)\n",
      " |-- newCol3: string (nullable = true)\n",
      " |-- newCol4: integer (nullable = true)\n",
      "\n",
      "'\\nnot working\\nold_columns = Seq(\"dob\",\"gender\",\"salary\",\"fname\",\"mname\",\"lname\")\\nnew_columns = Seq(\"DateOfBirth\",\"Sex\",\"salary\",\"firstName\",\"middleName\",\"lastName\")\\ncolumnsList = old_columns.zip(new_columns).map(f=>{col(f._1).as(f._2)})\\ndf5 = df4.select(columnsList:_*)\\ndf5.printSchema()\\n'\n"
     ]
    }
   ],
   "source": [
    "#Example 7\n",
    "newColumns = [\"newCol1\",\"newCol2\",\"newCol3\",\"newCol4\"]\n",
    "df.toDF(*newColumns).printSchema()\n",
    "\n",
    "# Example 6\n",
    "'''\n",
    "not working\n",
    "old_columns = Seq(\"dob\",\"gender\",\"salary\",\"fname\",\"mname\",\"lname\")\n",
    "new_columns = Seq(\"DateOfBirth\",\"Sex\",\"salary\",\"firstName\",\"middleName\",\"lastName\")\n",
    "columnsList = old_columns.zip(new_columns).map(f=>{col(f._1).as(f._2)})\n",
    "df5 = df4.select(columnsList:_*)\n",
    "df5.printSchema()\n",
    "'''\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be36e19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glue PySpark",
   "language": "python",
   "name": "glue_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
